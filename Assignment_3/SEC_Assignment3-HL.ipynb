{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Scraping the SEC Filings\n",
    "#### Group 1: Tara Bode, Hankun Li, and Roberto Bettaglio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up SEC File to Read and Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one 10-K (edit the path/filename)\n",
    "with open(r'/blue/acg7849/share/10Ks_sample/279117.html') as f:\n",
    "    full_filing = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 9591482\n"
     ]
    }
   ],
   "source": [
    "print ( type(full_filing) , len(full_filing) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the document (from start till first occurence of </DOCUMENT>\n",
    "# (often much smaller)\n",
    "filing = full_filing[0 : full_filing.find(\"</DOCUMENT\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2695874\n"
     ]
    }
   ],
   "source": [
    "print ( type(filing) , len(filing) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save this to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_example.html', \"w\") as f:\n",
    "    f.write(filing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoding the Business Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195288"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BD = Business Description\n",
    "\n",
    "# find the beginning \n",
    "startBD = filing.find('<a id=\"ITEM1\"></a>')\n",
    "startBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endBD = filing.find('<a id=\"ITEM1A\"></a>')\n",
    "endBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_section = filing[ startBD : endBD ]\n",
    "## save to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_business.html', \"w\") as f:\n",
    "    f.write(business_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: w3lib in ./.local/lib/python3.8/site-packages (1.22.0)\n",
      "Requirement already satisfied: first in ./.local/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: six>=1.4.1 in /apps/jupyterhub/1.1.0/lib/python3.8/site-packages (from w3lib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install w3lib first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, re\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "# function that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html and write as txt\n",
    "# here the encoding is needed to deal with special characters\n",
    "with open(r'/blue/acg7849/hli1/279117_business.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write( cleanhtml ( business_section) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print Business Section\n",
    "#print(cleanhtml(business_section))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoding the Central Index Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIK = Central Index Key\n",
    "\n",
    "# find the beginning \n",
    "startCIK = filing.find('CENTRAL INDEX KEY')\n",
    "startCIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endCIK = filing.find('STANDARD')\n",
    "endCIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_index_key = filing[ startCIK : endCIK ]\n",
    "## save to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_CIK.html', \"w\") as f:\n",
    "    f.write(central_index_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, re\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "# function that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html and write as txt\n",
    "# here the encoding is needed to deal with special characters\n",
    "with open(r'/blue/acg7849/hli1/279117_CIK.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write( cleanhtml ( central_index_key) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENTRAL INDEX KEY:\t\t\t0001001316\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "# print Central Index Key\n",
    "\n",
    "# print Company Conformed Name\n",
    "print(cleanhtml(central_index_key))\n",
    "\n",
    "#CIK = cleanhtml(central_index_key)\n",
    "\n",
    "\n",
    "#import re\n",
    "#WS = re.compile(r'\\s+')\n",
    "#CIK = re.sub(WS, ' ', CIK)\n",
    "#CIK.rstrip()\n",
    "\n",
    "#CIK = cleanhtml(central_index_key)\n",
    "#CIK.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoding the Company Conformed Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCN = Company Conformed Name\n",
    "\n",
    "# find the beginning \n",
    "startCCN = filing.find('COMPANY CONFORMED NAME')\n",
    "startCCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endCCN = filing.find('CENTRAL INDEX KEY')\n",
    "endCCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_conformed_name = filing[ startCCN : endCCN ]\n",
    "## save to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_CCN.html', \"w\") as f:\n",
    "    f.write(company_conformed_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, re\n",
    "# need to do: pip install w3lib first\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "# function that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html and write as txt\n",
    "# here the encoding is needed to deal with special characters\n",
    "with open(r'/blue/acg7849/hli1/279117_CCN.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write( cleanhtml ( company_conformed_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPANY CONFORMED NAME:\t\t\tTG THERAPEUTICS, INC.\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "# print Company Conformed Name\n",
    "print(cleanhtml(company_conformed_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoding the Conformed Submission Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CST = Conformed Submission Type\n",
    "\n",
    "# find the beginning \n",
    "startCST = filing.find('CONFORMED SUBMISSION TYPE')\n",
    "startCST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endCST = filing.find('PUBLIC DOCUMENT COUNT')\n",
    "endCST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformed_submission_type = filing[ startCST : endCST ]\n",
    "## save to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_CST.html', \"w\") as f:\n",
    "    f.write(conformed_submission_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, re\n",
    "# need to do: pip install w3lib first\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "# function that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html and write as txt\n",
    "# here the encoding is needed to deal with special characters\n",
    "with open(r'/blue/acg7849/hli1/279117_CST.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write( cleanhtml ( conformed_submission_type) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFORMED SUBMISSION TYPE:\t10-K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print Conformed Period of Report\n",
    "print(cleanhtml(conformed_submission_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoding the Conformed Period of Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPR = Conformed Period of Report\n",
    "\n",
    "# find the beginning \n",
    "startCPR = filing.find('CONFORMED PERIOD OF REPORT')\n",
    "startCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endCPR = filing.find('FILED AS OF DATE')\n",
    "endCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformed_period_report = filing[ startCPR : endCPR ]\n",
    "## save to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_CPR.html', \"w\") as f:\n",
    "    f.write(conformed_period_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, re\n",
    "# need to do: pip install w3lib first\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "# function that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html and write as txt\n",
    "# here the encoding is needed to deal with special characters\n",
    "with open(r'/blue/acg7849/hli1/279117_CPR.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write( cleanhtml ( conformed_period_report) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFORMED PERIOD OF REPORT:\t20191231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print Conformed Period of Report\n",
    "print(cleanhtml(conformed_period_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoding the Length of the Business Description Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195288"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LBD = Length of Business Description\n",
    "\n",
    "# USE REGEX TO FIND LENGTH\n",
    "\n",
    "# find the beginning \n",
    "startLBD = filing.find('<a id=\"ITEM1\"></a>')\n",
    "startLBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439847"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endLBD = filing.find('<a id=\"ITEM1A\"></a>')\n",
    "endLBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_business_section = filing[ startLBD : endLBD ]\n",
    "## save to disk to inspect (without browser crashing)\n",
    "with open(r'/blue/acg7849/hli1/279117_LBD.html', \"w\") as f:\n",
    "    f.write(length_business_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, re\n",
    "# need to do: pip install w3lib first\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "# function that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html and write as txt\n",
    "# here the encoding is needed to deal with special characters\n",
    "with open(r'/blue/acg7849/hli1/279117_LBD.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write( cleanhtml ( length_business_section) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132333\n",
      "Length of Business Description: 132333 \n"
     ]
    }
   ],
   "source": [
    "#print(cleanhtml(length_business_section))\n",
    "\n",
    "# Print out number of characters only\n",
    "print(len(cleanhtml(length_business_section)))\n",
    "\n",
    "# Print out refined count of characters\n",
    "length = len(cleanhtml(length_business_section))\n",
    "print('Length of Business Description: {0} ' .format(length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to combine all business description file into 1 file --can be .txt or .html-- Joost doesn't have a preference\n",
    "# Need to make CSV that combines the remaining 5 pieces of information\n",
    "\n",
    "# Make sure they are in the path '/blue/acg7849/tbode/item1/' -- will put under my directory for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileNo.</th>\n",
       "      <th>CCN</th>\n",
       "      <th>CIK</th>\n",
       "      <th>CPR</th>\n",
       "      <th>CST</th>\n",
       "      <th>LBD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FileNo., CCN, CIK, CPR, CST, LBD]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make final csv -  HL\n",
    "import pandas as pd\n",
    "Fintable = pd.DataFrame(columns = ['FileNo.', 'CCN', 'CIK', 'CPR', 'CST', 'LBD'])\n",
    "Fintable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileNo.</th>\n",
       "      <th>CCN</th>\n",
       "      <th>CIK</th>\n",
       "      <th>CPR</th>\n",
       "      <th>CST</th>\n",
       "      <th>LBD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FileNo.  CCN  CIK  CPR  CST   LBD\n",
       "0     100  199  100  100  100  1000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test example of the csv\n",
    "data1 = {'FileNo.':[100],\n",
    "        'CCN':[199],\n",
    "        'CIK':[100],\n",
    "        'CPR':[100],\n",
    "        'CST':[100],\n",
    "        'LBD':[1000]}\n",
    "  \n",
    "Other = pd.DataFrame(data1, columns = ['FileNo.', 'CCN', 'CIK', 'CPR', 'CST', 'LBD'])\n",
    "#df = df.append({'A': i}, ignore_index=True)\n",
    "Fintable = Fintable.append(Other)\n",
    "Fintable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(columns=['lib', 'qty1', 'qty2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue/acg7849/share/10Ks/*.txt\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#read automation\n",
    "import glob as glob\n",
    "directory = 'blue/acg7849/share/10Ks/'\n",
    "d1 = '*.txt'\n",
    "d = \"\".join((directory,d1))\n",
    "print (d)\n",
    "full_filing = glob.glob(d)\n",
    "\n",
    "print(full_filing) # why is it empty!\n",
    "\n",
    "#filing  = full_filing[0:full_filing.find('</DOCUMENT')]  # 'list' object has no attribute 'find'\n",
    "filing  = full_filing[0:5] # use a number as alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"/blue/acg7849/share/10Ks/\"\n",
    "savepath = \"/blue/acg7849/hli1/folder\"\n",
    "for files in glob.glob(path +\"*.txt\"):\n",
    "    infile = open(files)\n",
    "    outfile = open(savepath,'w')\n",
    "    a = infile.readline().split('.')\n",
    "    for k in range (0,len(a)):\n",
    "        print(a[0], file=outfile, end='')\n",
    "infile.close()\n",
    "outfile.close\n",
    "print (\"done\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in ./.local/lib/python3.8/site-packages (0.8.9)\n"
     ]
    }
   ],
   "source": [
    "! pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "\n",
    "with open(\"/blue/acg7849/hli1/279117_business.txt\",\"r\") as input:\n",
    "    with open(\"/blue/acg7849/hli1/279117_business.txt\",\"wb\") as output:\n",
    "        for line in input:\n",
    "            if line != str(x) + \"\\n\":\n",
    "                output.write(line + \"\\n\")\n",
    "                x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filing = (tabulate(full_filing, tablefmt='html'))\n",
    "with open (r'/blue/acg7849/hli1/Company_info.html', \"w\") as f1:\n",
    "    f1.write(full_filing)  # empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in ./.local/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.local/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in ./.local/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "file isolation not edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file isolation\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '/blue/acg7849/hli1/279117_example.html': No schema supplied. Perhaps you meant http:///blue/acg7849/hli1/279117_example.html?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-204dfd4b43c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mURL_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/blue/acg7849/hli1/279117_example.html'\u001b[0m  \u001b[0;31m# invalid url?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Grab the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Parse the response (the XML flag works better than HTML for 10Ks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         )\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         p.prepare(\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '/blue/acg7849/hli1/279117_example.html': No schema supplied. Perhaps you meant http:///blue/acg7849/hli1/279117_example.html?"
     ]
    }
   ],
   "source": [
    "# Define URL for the specific 10K filing\n",
    "URL_text = r'/blue/acg7849/hli1/279117_example.html'  # invalid url?\n",
    "# Grab the response\n",
    "response = requests.get(URL_text)\n",
    "# Parse the response (the XML flag works better than HTML for 10Ks)\n",
    "soup = BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c6a4dd54b695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfiling_document\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;31m# The 'type' tag contains the document type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdocument_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiling_document\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "for filing_document in soup.find_all('document'):\n",
    "  # The 'type' tag contains the document type\n",
    "  document_type = filing_document.type.find(text=True, recursive=False).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-462b50729bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdocument_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"10-K\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Once the 10K text body is found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Grab and store the 10K text body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mTenKtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiling_document\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document_type' is not defined"
     ]
    }
   ],
   "source": [
    "if document_type == \"10-K\":  # Once the 10K text body is found\n",
    "\n",
    "  # Grab and store the 10K text body    \n",
    "  TenKtext = filing_document.find('text').extract().text\n",
    "    \n",
    "matches = re.compile(r'(item\\s(7[\\.\\s]|8[\\.\\s])|discussion\\sand\\sanalysis\\sof\\s(consolidated\\sfinancial|financial)\\scondition|(consolidated\\sfinancial|financial)\\sstatements\\sand\\ssupplementary\\sdata)', re.IGNORECASE)\n",
    "\n",
    "matches_array = pd.DataFrame([(match.group(), match.start()) for match in matches.finditer(TenKtext)])# Set columns in the dataframe\n",
    "matches_array.columns = ['SearchTerm', 'Start']# Get the number of rows in the dataframe\n",
    "Rows = matches_array['SearchTerm'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in 'matches_array' called 'Selection' and add adjacent 'SerchTerm' (i and i+1 rows) text concatenated\n",
    "count = 0 # Counter to help with row location and iteration\n",
    "while count < (Rows-1): # Can only iterate to the second last row\n",
    "  matches_array.at[count,'Selection'] = (matches_array.iloc[count,0] + matches_array.iloc[count+1,0]).lower() # Convert to lower case\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 'Item 7/8 Search Pattern' regex patterns\n",
    "matches_item7 = re.compile(r'(item\\s7\\.discussion\\s[a-z]*)')\n",
    "matches_item8 = re.compile(r'(item\\s8\\.(consolidated\\sfinancial|financial)\\s[a-z]*)')\n",
    "            \n",
    "# Lists to store the locations of Item 7/8 Search Pattern matches\n",
    "Start_Loc = []\n",
    "End_Loc = []\n",
    "# Find and store the locations of Item 7/8 Search Pattern matches\n",
    "count = 0 # Set up counter\n",
    "while count < (Rows-1): # Can only iterate to the second last row \n",
    "  # Match Item 7 Search Pattern\n",
    "  if re.match(matches_item7, matches_array.at[count,'Selection']):\n",
    "    # Column 1 = 'Start' column in 'matches_array'\n",
    "    Start_Loc.append(matches_array.iloc[count,1])\n",
    "  \n",
    "  # Match Item 8 Search Pattern\n",
    "  if re.match(matches_item8, matches_array.at[count,'Selection']):  \n",
    "    End_Loc.append(matches_array.iloc[count,1])\n",
    "  \n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleansing\n",
    "\n",
    "TenKItem7 = TenKtext[Start_Loc[1]:End_Loc[1]]\n",
    "TenKItem7 = TenKItem7.strip() # Remove start/end white space\n",
    "TenKItem7 = TenKItem7.replace('\\n', ' ') # Replace \\n with space\n",
    "TenKItem7 = TenKItem7.replace('\\r', '') # \\r => space\n",
    "TenKItem7 = TenKItem7.replace(' ', ' ') # \" \" => space\n",
    "TenKItem7 = TenKItem7.replace(' ', ' ') # \" \" => space\n",
    "  while '  ' in TenKItem7:\n",
    "    TenKItem7 = TenKItem7.replace('  ', ' ') # Remove extra spaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (basic)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
