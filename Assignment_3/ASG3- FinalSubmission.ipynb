{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Scraping the SEC Filings\n",
    "#### Group 1: Tara Bode, Hankun Li, and Roberto Bettaglio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: w3lib in ./.local/lib/python3.8/site-packages (1.21.0)\n",
      "Requirement already satisfied: first in ./.local/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: six>=1.4.1 in /apps/jupyterhub/1.1.0/lib/python3.8/site-packages (from w3lib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Packages\n",
    "\n",
    "!pip install w3lib first\n",
    "\n",
    "import html, re\n",
    "# need to do: pip install w3lib first\n",
    "from w3lib.html import replace_entities\n",
    "\n",
    "import csv\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydirectory = '/blue/acg7849/share/10Ks'\n",
    "file_list = glob.glob(mydirectory + '/*.txt')\n",
    "#print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeaderVariables(filing):\n",
    "    CIK = filing[ filing.find('CENTRAL INDEX KEY:') + 18  : filing.find('STANDARD') ]\n",
    "    CIK = ''.join(CIK.split())\n",
    "    #\n",
    "    CCN = filing[ filing.find('COMPANY CONFORMED NAME:') + 23 : filing.find('CENTRAL INDEX KEY') ]\n",
    "    CCN = CCN.rstrip().lstrip()\n",
    "    #\n",
    "    CST = filing[ filing.find('CONFORMED SUBMISSION TYPE:') + 26 : filing.find('PUBLIC DOCUMENT COUNT') ]\n",
    "    CST = ''.join(CST.split())\n",
    "    #\n",
    "    CPR = filing[ filing.find('CONFORMED PERIOD OF REPORT:') + 27 : filing.find('FILED AS OF DATE') ]\n",
    "    CPR = ''.join(CPR.split())\n",
    "    #\n",
    "    Length = 'skip'\n",
    "    \n",
    "    sec_info = '{} | {} | {} | {} | {}\\n'.format(CIK, CCN, CST, CPR, Length)\n",
    "    return (sec_info)\n",
    "\n",
    "def cleanHTML(raw_html):\n",
    "    cleanr = re.compile('<.*?>', flags=re.DOTALL)\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)\n",
    "    \n",
    "def getBusinessSection(filing):\n",
    "    # USE REGEXR\n",
    "    BDS = filing[ filing.find('Item 1. ') : filing.find('Item 1A. ') ]\n",
    "    #print('length_business_section',len(BDS))\n",
    "    #print(BDS)\n",
    "    return BDS\n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the SEC Information to Main File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write header variables and length of business section to disk\n",
    "with open (r'/blue/acg7849/tbode/SEC_Information.csv', 'w') as f:\n",
    "    f.write('File Name | Central Index Key | Company Name | Submission Type | Period of Report | Length of Business Description\\n')\n",
    "\n",
    "for file_path in file_list[0:1000]:\n",
    "    # read the file\n",
    "    with open(file_path) as f:\n",
    "        filing = f.read()\n",
    "        \n",
    "    # only use until /DOCUMENT\n",
    "    first_section = filing[0: filing.find('</DOCUMENT')]\n",
    "    \n",
    "    # get header variables\n",
    "    headervars = str(getHeaderVariables(first_section))\n",
    "    \n",
    "    # isolate business section\n",
    "    business_section = str(getBusinessSection(first_section))\n",
    "    \n",
    "    #need to input FileName\n",
    "    shortName = file_path[file_path.rfind(\"/\")+1:]\n",
    "    \n",
    "    # write business section to disk       \n",
    "    with open(r'/blue/acg7849/tbode/item1/'+ shortName, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(cleanHTML(business_section))\n",
    "   \n",
    "    with open (r'/blue/acg7849/tbode/SEC_Information.csv', 'a', encoding=\"utf-8\") as f:\n",
    "        f.write(shortName + ' | ' + cleanHTML(headervars))\n",
    "\n",
    "    #with open (r'/blue/acg7849/tbode/SEC_Information.csv', 'a', encoding=\"utf-8\") as f:\n",
    "     #   f.write(shortName + ' | ' + cleanHTML(headervars) + ' | ' + len(cleanHTML(business_section)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Trial Runs for REGEX for Business Section that were Unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business = '(?<=<a name=\"ITEM 1. DESCRIPTION OF BUSINESS.\">)(.*?)(?=</a name=\"ITEM 1A. Risk Factors\">)'\n",
    "#business = '<[p style=\"MARGIN: 0px 0px 0px 0in\" align=\"justify\">&nbsp;</p> <p style=\"MARGIN: 0px 0px 0px 0in\" align=\"justify\">\">]*>(.+?)<[</p> <p style=\"MARGIN: 0px 0px 0px 0in\" align=\"justify\">&nbsp;</p>]>'\n",
    "#regexp = \\{<p style=\"MARGIN: 0px 0px 0px 0in\" align=\"justify\">}(.*?)\\{</p>}\\m\n",
    "#regexp = '<a name=\"ITEM 1. DESCRIPTION OF BUSINESS.\">(.*?)<p style=\"MARGIN: 0px 0px 0px 0in\" align=\"justify\">'\n",
    "#regexp = '<a name=\"PART 1\">(.*?)<a name=\"ITEM 1A. Risk Factors\">'\n",
    "#regexp = '<b><a name=\"ITEM 1. DESCRIPTION OF BUSINESS.\">(.*?)<a name=\"ITEM 1A. Risk Factors\">'\n",
    "\n",
    "line = file.read()\n",
    "\n",
    "regexp = '(ITEM 1. DESCRIPTION OF BUSINESS.<)(.*?)(ITEM 1A. Risk Factors)'\n",
    "# Clean newly extracted text\n",
    "regexp = regexp.strip() # Remove starting/ending white spaces\n",
    "regexp = regexp.replace('\\n', ' ') # Replace \\n (new line) with space\n",
    "regexp = regexp.replace('\\r', '') # Replace \\r (carriage returns-if you're on windows) with space\n",
    "regexp = regexp.replace(' ', ' ') # Replace \" \" (a special character for space in HTML) with space\n",
    "regexp = regexp.replace(' ', ' ') # Replace \" \" (a special character for space in HTML) with space\n",
    "while '  ' in regexp:\n",
    "    regexp = regexp.replace('  ', ' ') # Remove extra spaces\n",
    "\n",
    "# Print first 500 characters of newly extracted text\n",
    "print(regexp[:50])\n",
    "\n",
    "sig = re.findall(regexp, line)\n",
    "sig\n",
    "#sig.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Section Regex Statement  ~ researched from https://gist.github.com/TobagoMango/7dd2dfe1e8174114f8f39fa8c5edcec8 ~\n",
    "# wasn't able to run due to parsing issues - not sure how to adjust, as I tried different parsing combinations\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define URL for the specific 10K filing\n",
    "URL_text = glob.glob(mydirectory + '/*.txt')\n",
    "\n",
    "# Grab the response\n",
    "response = requests.get(URL_text)\n",
    "\n",
    "# Parse the response\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "for filing_document in soup.find_all('document'): \n",
    "    \n",
    "    # The 'type' tag contains the document type\n",
    "    document_type = filing_document.type.find(text=True, recursive=False).strip()\n",
    "    \n",
    "    if document_type == \"10-K\": # Once the 10K text body is found\n",
    "        \n",
    "        # Set up the regex pattern\n",
    "        matches = re.compile(r'item\\s(1[\\.\\s]|1a[\\.\\s])|(description\\sof\\sbusiness|business)|(risk\\sfactors)', re.IGNORECASE)\n",
    "    \n",
    "        matches_array = pd.DataFrame([(match.group(), match.start()) for match in matches.finditer(filing)])\n",
    "    \n",
    "        # Set columns in the dataframe\n",
    "        matches_array.columns = ['SearchTerm', 'Start']\n",
    "        \n",
    "        # Get the number of rows in the dataframe\n",
    "        Rows = matches_array['SearchTerm'].count()\n",
    "        print(Rows)\n",
    "    \n",
    "        # Create a new column in 'matches_array' called 'Selection' and add adjacent 'SearchTerm' (i and i+1 rows) text concatenated\n",
    "        count = 0 # Counter to help with row location and iteration\n",
    "        while count < (Rows-1): # Can only iterate to the second last row\n",
    "            matches_array.at[count,'Selection'] = (matches_array.iloc[count,0] + matches_array.iloc[count+1,0]).lower() # Convert to lower case\n",
    "            count += 1\n",
    "        \n",
    "        # Set up 'Item 1/1A Search Pattern' regex patterns\n",
    "        matches_item1 = re.compile(r'(item\\s1\\.(description\\sof\\sbusiness|business)|[a-z]*)')\n",
    "        matches_item1a = re.compile(r'(item\\s1a\\.(risk\\sfactors)[a-z]*)')\n",
    "            \n",
    "        # Lists to store the locations of Item 1/1A Search Pattern matches\n",
    "        Start_Loc = []\n",
    "        End_Loc = []\n",
    "    \n",
    "        # Find and store the locations of Item 1/1A Search Pattern matches\n",
    "        count = 0 # Set up counter\n",
    "        \n",
    "        while count < (Rows-1): # Can only iterate to the second last row\n",
    "            \n",
    "            # Match Item 1 Search Pattern\n",
    "            if re.match(matches_item1, matches_array.at[count,'Selection']):\n",
    "                # Column 1 = 'Start' columnn in 'matches_array'\n",
    "                Start_Loc.append(matches_array.iloc[count,1]) # Store in list => Item 7 will be the starting location (column '1' = 'Start' column)\n",
    "            \n",
    "            # Match Item 1a Search Pattern\n",
    "            if re.match(matches_item1a, matches_array.at[count,'Selection']):\n",
    "                End_Loc.append(matches_array.iloc[count,1])\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "        # Extract section of text and store in 'TenKItem1'\n",
    "        TenKItem1 = file_list[Start_Loc[1]:End_Loc[1]]\n",
    "        \n",
    "        # Clean newly extracted text\n",
    "        TenKItem1 = TenKItem1.strip() # Remove starting/ending white spaces\n",
    "        TenKItem1 = TenKItem1.replace('\\n', ' ') # Replace \\n (new line) with space\n",
    "        TenKItem1 = TenKItem1.replace('\\r', '') # Replace \\r (carriage returns-if you're on windows) with space\n",
    "        TenKItem1 = TenKItem1.replace(' ', ' ') # Replace \" \" (a special character for space in HTML) with space\n",
    "        TenKItem1 = TenKItem1.replace(' ', ' ') # Replace \" \" (a special character for space in HTML) with space\n",
    "        while '  ' in TenKItem1:\n",
    "            TenKItem1 = TenKItem1.replace('  ', ' ') # Remove extra spaces\n",
    "\n",
    "        # Print first 50 characters of extracted text\n",
    "        print(TenKItem1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (basic)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
