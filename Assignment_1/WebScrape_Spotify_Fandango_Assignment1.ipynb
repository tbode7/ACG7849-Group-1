{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a8b4e1",
   "metadata": {},
   "source": [
    "# SPOTIFY\n",
    "### Group 1:\n",
    "Zachary Wilkerson, Tara Bode, Hankun Li\n",
    "\n",
    "### Some things I want to know:\n",
    "- How many times did a track stay in the daily global top 200 list in 2021?\n",
    "- How many times did an artist stay in the daily global top 200 list in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef906c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "options = webdriver.ChromeOptions();\n",
    "options.add_argument(\"disable-geolocation\");\n",
    "options.add_argument(\"disable-notifications\");\n",
    "\n",
    "driver = webdriver.Chrome(r'/Users/zwilkerson/Desktop/UF/ACG7849 - Web Crawling and Textual Analysis/selenium_files/chromedriver',options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3adadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://spotifycharts.com/regional/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1525efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_adder(key,dic):\n",
    "    try:\n",
    "        dic[key] += 1;\n",
    "    except:\n",
    "        dic[key] = 1;\n",
    "    return dic\n",
    "\n",
    "def button_clicking(driver,index):\n",
    "    button = driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/div/span/div[1]/div/div/div/div[3]')\n",
    "    button.click()\n",
    "    new_button = driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/div/span/div[1]/div/div/div/div[3]/ul/li['+str(date_index)+']')\n",
    "    date = new_button.get_attribute('innerHTML');\n",
    "    return date,button,new_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e09898",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_dict = {};\n",
    "artist_dict = {};\n",
    "\n",
    "date_index = 1;\n",
    "[date,date_button,newdate_button] = button_clicking(driver,date_index)\n",
    "date_index = 1;\n",
    "\n",
    "#while re.search(r'[0-9]{2}/[0-9]{2}/2021',date):\n",
    "while re.search(r'[0-9]{2}/[0-9]{2}/2021',date):\n",
    "    newdate_button.click()\n",
    "\n",
    "    # ranking = driver.find_elements_by_xpath('//*[@id=\"content\"]/div/div/div/span/table/tbody/tr/td[2]')\n",
    "    info = driver.find_elements_by_xpath('//*[@id=\"content\"]/div/div/div/span/table/tbody/tr/td[4]')\n",
    "    # streams = driver.find_elements_by_xpath('//*[@id=\"content\"]/div/div/div/span/table/tbody/tr/td[5]')\n",
    "\n",
    "    # ranking_list = [];\n",
    "    # streams_list = [];\n",
    "\n",
    "    for item in range(len(info)):\n",
    "        song_artist_split = info[item].text.split(' by ')\n",
    "        dict_adder(song_artist_split[0],song_dict)\n",
    "        dict_adder(song_artist_split[1],artist_dict)\n",
    "        # ranking_list.append(ranking[item].text)\n",
    "        # streams_list.append(streams[item].text)\n",
    "    \n",
    "    date_index +=1;\n",
    "    [date,date_button,newdate_button] = button_clicking(driver,date_index)\n",
    "\n",
    "date_button.click()\n",
    "driver.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea94d0",
   "metadata": {},
   "source": [
    "## Let's take a look at our data!\n",
    "Uncomment and run the following lines if you'd like. \n",
    "\n",
    "If not, take a look at the printed top artists and songs!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa9e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#artist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d122257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#song_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1c90d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top 5 Artists]\n",
      "\n",
      "Justin Bieber \t - \t 749 occurances\n",
      "Juice WRLD \t - \t 667 occurances\n",
      "Billie Eilish \t - \t 618 occurances\n",
      "Pop Smoke \t - \t 604 occurances\n",
      "Ariana Grande \t - \t 600 occurances\n",
      "__________________________________________________________________________\n",
      "\n",
      "[Top 5 Songs]\n",
      "\n",
      "Falling \t - \t 248 occurances\n",
      "Levitating (feat. DaBaby) \t - \t 134 occurances\n",
      "Blinding Lights \t - \t 134 occurances\n",
      "The Business \t - \t 134 occurances\n",
      "D√ÅKITI \t - \t 134 occurances\n"
     ]
    }
   ],
   "source": [
    "# SEE: https://careerkarma.com/blog/python-sort-a-dictionary-by-value/#:~:text=To%20sort%20a%20dictionary%20by%20value%20in%20Python%20you%20can,Dictionaries%20are%20unordered%20data%20structures.\n",
    "top_artists = sorted(artist_dict.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "top_songs = sorted(song_dict.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "print('[Top 5 Artists]\\n')\n",
    "for i in top_artists:\n",
    "    print('{} \\t - \\t {} occurances'.format(i[0], i[1]))\n",
    "\n",
    "print('__________________________________________________________________________')\n",
    "    \n",
    "print('\\n[Top 5 Songs]\\n')\n",
    "for i in top_songs:\n",
    "    print('{} \\t - \\t {} occurances'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60aee3",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3849d1",
   "metadata": {},
   "source": [
    "# FANDANGO\n",
    "### Group 1:\n",
    "Zachary Wilkerson, Tara Bode, Hankun Li\n",
    "\n",
    "### Some things I want to know:\n",
    "- ### \n",
    "- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time # needed for time.sleep\n",
    "from selenium import webdriver\n",
    "# new driver (opens browser window)\n",
    "driver = webdriver.Chrome(r'/Users/zwilkerson/Desktop/UF/ACG7849 - Web Crawling and Textual Analysis/selenium_files/chromedriver')\n",
    "driver.get(\"https://www.fandango.com/movie-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first hyperlink\n",
    "el = driver.find_element_by_tag_name(\"a\")\n",
    "print (el)\n",
    "print ( el.get_attribute(\"href\") )\n",
    "\n",
    "elements = driver.find_elements_by_tag_name(\"a\")\n",
    "len(elements)\n",
    "\n",
    "pagesToCrawl = []\n",
    "for el in elements[0:331]:\n",
    "    parent = el.find_element_by_xpath('..') \n",
    "    if el.get_attribute(\"class\")==\"cta mrp__table-movie-reviews-link\":      \n",
    "        pagesToCrawl.append(el.get_attribute(\"href\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48337f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create keyword lists\n",
    "positive = ['love','fun','good','quality','great']\n",
    "extra_positive = ['phenomenal','top','heartwarming','favorite','awesome']\n",
    "\n",
    "negative = [ 'horrible', 'predictable', 'boring', 'bad']\n",
    "extra_negative = [ 'disappointing', 'worst', 'waste', 'awful','terrible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = []\n",
    "critic_score_list = []\n",
    "audience_score_list = []\n",
    "positiveReviews = []\n",
    "extraPositiveReviews = []\n",
    "negativeReviews = []\n",
    "extraNegativeReviews = []\n",
    "\n",
    "#for item in range(len(pagesToCrawl)):\n",
    "for item in range(len(pagesToCrawl)):\n",
    "    positiveReviewsCnt = 0\n",
    "    extraPositiveReviewsCnt = 0\n",
    "    negativeReviewsCnt = 0\n",
    "    extraNegativeReviewsCnt = 0\n",
    "    \n",
    "    driver.get(pagesToCrawl[item])\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        critic_score = driver.find_elements_by_class_name('movie-ratings-tabs__rating')[0].text\n",
    "        audience_score = driver.find_elements_by_class_name('movie-ratings-tabs__rating')[1].text\n",
    "        movie_list.append(driver.find_element_by_xpath('//*[@id=\"subnav\"]/div/div/h1/a').get_attribute('data-name'));\n",
    "        critic_score_list.append(critic_score);\n",
    "        audience_score_list.append(audience_score);\n",
    "        review_list = driver.find_elements_by_class_name('rt-audience-reviews__content')\n",
    "        #print(len(review_list))\n",
    "        for review in review_list:\n",
    "            #print('Review: '+review.text)\n",
    "            #print(review.text.count('bad'))\n",
    "            text = review.text\n",
    "            for word in positive: \n",
    "                positiveReviewsCnt += text.count(word)\n",
    "            for word in extra_positive: \n",
    "                extraPositiveReviewsCnt += text.count(word)\n",
    "            for word in negative: \n",
    "                negativeReviewsCnt += text.count(word) \n",
    "            for word in extra_negative: \n",
    "                extraNegativeReviewsCnt += text.count(word)\n",
    "            #print('NEGATIVE REVIEWS COUNT: '+str(negativeReviewsCnt))\n",
    "        positiveReviews.append(positiveReviewsCnt)\n",
    "        extraPositiveReviews.append(extraPositiveReviewsCnt)\n",
    "        negativeReviews.append(negativeReviewsCnt)\n",
    "        extraNegativeReviews.append(extraNegativeReviewsCnt)\n",
    "    except:\n",
    "        print('No rating score to display for '+pagesToCrawl[item]+' . . . \\n')\n",
    "        movie_list.append(driver.find_element_by_xpath('//*[@id=\"subnav\"]/div/div/h1/a').get_attribute('data-name'));\n",
    "        critic_score_list.append('N/A');\n",
    "        audience_score_list.append('-');\n",
    "        positiveReviews.append('-')\n",
    "        extraPositiveReviews.append('-')\n",
    "        negativeReviews.append('-')\n",
    "        extraNegativeReviews.append('-')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd48875",
   "metadata": {},
   "outputs": [],
   "source": [
    "webcrawl = pd.DataFrame(list(zip(movie_list,critic_score_list,audience_score_list,positiveReviews,extraPositiveReviews,negativeReviews,extraNegativeReviews)), columns=['Movie Name','Critic Rating','Audience Rating','Number of Positive Reviews','Number of Extra Positive Reviews','Number of Negative Reviews','Number of Extra Negative Reviews']);\n",
    "display(webcrawl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
