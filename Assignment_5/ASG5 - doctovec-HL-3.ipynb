{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASG5 part3\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster the business sections (/blue/acg7849/share/BS) using Doc2Vec (50 clusters) in two ways:\n",
    "\n",
    "Using a counter as the ‘tag’ (as in 5.1.5)\n",
    "\n",
    "Using a counter as the ‘tag’, and the industry code as an additional tag (yield TaggedDocument(words=file_tokens, tags=[i, SIC]) where SIC is a string holding the tag (for example ‘1740’)\n",
    "\n",
    "Extract the 4-digit SIC industry code from the annual report header (STANDARD INDUSTRIAL CLASSIFICATION).\n",
    "\n",
    "Required: Evaluate whether adding the industry code as an additional tag improves the clustering. Use the standard deviation of profitability as a way to evaluate this. (Firms that are more similar, should have similar performance. Therefore, a better clustering would result in lower standard deviations for each cluster, relative to a worse clustering).\n",
    "\n",
    "Do this for the filings for the year 2019 only. Calculate the standard deviation of performance for each cluster (use the year of CONFORMED END OF PERIOD, which are the first 4 digits of ‘date’ in summary.text).\n",
    "\n",
    "For 50 clusters that means you will have 2 standard deviations for each cluster (one for each approach, with the extra SIC tag vs not adding the extra SIC tag). Use a t-test to test for a difference between the two sets of 50 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/1.1.0/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# all imports\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import html, re\n",
    "from w3lib.html import replace_entities\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from scipy.cluster import  hierarchy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "stopWords = set(stopwords.words('english') )\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk import FreqDist\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# already made this - copy + paste to personal directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#try copy and past targets\n",
    "#think this is a pretty bold way avoiding messing up with the class\n",
    "\n",
    "import shutil\n",
    "for i in range(len(listoflink)):\n",
    "    shutil.copy(listoflink[i], r'/blue/acg7849/hli1/item1')\n",
    "    #shutil.copy(listoflink[i], r'/blue/acg7849/tbode/whateverfile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codes from 515 - start with new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some punctuation to string.punctuation\n",
    "punc = string.punctuation + '“”'\n",
    "\n",
    "# documents get tagged by an index (number), while filenames have different numbers\n",
    "# keep track of this\n",
    "fileIdToIndex = {} # given a fileId -> tag\n",
    "indexToFileId=[] # given a tag -> fileId\n",
    "\n",
    "class MyFiles(object):\n",
    "    def __init__(self, dirname, tokens_only = False):\n",
    "        self.dirname = dirname\n",
    "        self.tokens_only = tokens_only\n",
    " \n",
    "    def __iter__(self):\n",
    "        #for i, fname in enumerate(files[0:200]):\n",
    "         \n",
    "        for i, fname in enumerate(os.listdir(self.dirname)[0:200]):    # there are 4604 files in total\n",
    "        # enumerate = return a list of tuples, iterate from start to end\n",
    "        # os.listdir = return index of a directory, input = directory address\n",
    "        # this part enumerates the first 200 units in the index under dirname\n",
    "        \n",
    "            with open( os.path.join(self.dirname, fname), encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            # filter\n",
    "                #content = [f for f in content if int(f[\"length\"])> 1000 and (f[\"date\"][0:4]) == '2019']\n",
    "                #content = [f for f in content if len(f)> 1000]\n",
    "            # grab id from filename\n",
    "            myCounter = int ( re.findall(r'(\\d*)\\.txt', fname)[0] )\n",
    "            # update \n",
    "            fileIdToIndex [ myCounter] = i\n",
    "            indexToFileId.append( myCounter)\n",
    "            #print('fname', fname, 'tag', myCounter)\n",
    "            file_tokens = [x for x in word_tokenize(content) if x.isalpha() and x.lower() not in stopWords and x not in string.punctuation]\n",
    "            \n",
    "            if self.tokens_only == True:\n",
    "                yield file_tokens\n",
    "            else:\n",
    "                yield TaggedDocument(words=file_tokens, tags=[i] )                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipergator\n",
    "ffiles = MyFiles(r'/blue/acg7849/hli1/item1') # this one expected str, bytes or os.PathLike object\n",
    "#ffiles = MyFiles(r'/blue/acg7849/share/BS/item1/') # a memory-friendly iterator\n",
    "# dirname = '/blue/acg7849/share/BS/item1/'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model, build vocabulary\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=8)\n",
    "model.build_vocab(ffiles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH\n"
     ]
    }
   ],
   "source": [
    "# train it\n",
    "model.train(ffiles, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "print('FINISH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipergator\n",
    "def tokenizeFile(file_id):\n",
    "    with open( r'/blue/acg7849/hli1/item1/'+str(file_id)+'.txt', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    return ([x for x in word_tokenize(content) if x.isalpha() and x.lower() not in stopWords and x not in string.punctuation] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4767705 , -0.0115789 , -1.7262841 , -1.2262379 ,  2.7107096 ,\n",
       "       -1.9205048 , -2.519832  , -1.2013861 , -2.6640322 ,  0.6726109 ,\n",
       "       -0.26111737,  2.4964356 , -0.9154145 ,  1.1359534 ,  0.39194626,\n",
       "        0.40125725,  0.6422191 ,  2.1713967 , -1.7170639 , -4.838732  ,\n",
       "       -0.6639528 ,  0.3315963 ,  0.13589436,  0.36715427, -0.19252302,\n",
       "       -0.42660287, -1.3432615 ,  0.23694478, -1.6745603 ,  0.94445527,\n",
       "        0.80584824,  1.6799648 , -0.938454  , -1.531435  ,  0.79121536,\n",
       "       -1.4815254 , -0.2635625 , -2.859668  ,  1.7009642 ,  0.3152727 ,\n",
       "       -0.7396305 , -0.62165445,  1.823005  ,  1.5146507 ,  0.10767917,\n",
       "       -2.9715924 ,  0.37576294,  2.1433923 ,  0.46156064,  0.37237906,\n",
       "       -1.0037848 ,  1.487787  ,  0.89794105,  0.5859917 , -2.128481  ,\n",
       "       -0.28554684, -1.5388486 ,  1.994815  , -0.8447659 ,  1.6837491 ,\n",
       "        3.272897  ,  0.42764863,  2.0898871 , -1.1646743 , -1.0380759 ,\n",
       "       -0.9085714 ,  1.0646596 ,  0.5012265 ,  0.31648484,  0.26886377,\n",
       "       -2.40961   ,  0.8466937 , -0.29678637, -1.1851866 ,  1.1688122 ,\n",
       "       -0.5921405 , -0.43958792, -2.1762118 , -0.22830276,  0.50365996,\n",
       "        0.71305   ,  0.5861997 ,  0.6478161 , -0.8883706 ,  0.91956234,\n",
       "        3.5786126 , -1.5853417 , -1.4067057 , -0.8193004 , -0.5604907 ,\n",
       "       -2.0430405 ,  3.7937753 , -1.4736962 , -1.6664555 ,  0.6492007 ,\n",
       "        0.74854183, -1.2552865 ,  0.26148793,  0.36391127, -0.12448375],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizeFile(277350) # test file = 277350\n",
    "model.infer_vector( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(180, 0.7388142943382263),\n",
       " (3, 0.7200323939323425),\n",
       " (107, 0.6929206252098083),\n",
       " (26, 0.6576422452926636),\n",
       " (37, 0.6475551128387451)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizeFile(277350)\n",
    "inferred_vector = model.infer_vector( t )\n",
    "# dv is short for docvecs\n",
    "# most similar files to 277350 is the 4th one 265065?\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "#sims = model.dv.most_similar([inferred_vector], topn=4)\n",
    "sims[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0bceb90a8426>:2: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  similar_doc = model.docvecs.most_similar(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(103, 0.8445403575897217),\n",
       " (93, 0.8397471904754639),\n",
       " (149, 0.8357316851615906),\n",
       " (107, 0.8090888857841492),\n",
       " (198, 0.7986845374107361),\n",
       " (55, 0.7941851615905762),\n",
       " (115, 0.7887516021728516),\n",
       " (90, 0.7636479735374451),\n",
       " (47, 0.7595515251159668),\n",
       " (37, 0.7589263916015625)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# letter with filename 1.txt is the first letter, so tag is 0\n",
    "similar_doc = model.docvecs.most_similar(0)\n",
    "similar_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents 200\n",
      "model.docvecs 200\n"
     ]
    }
   ],
   "source": [
    "print('number of documents', model.corpus_count)\n",
    "print('model.docvecs', len(model.dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.28004587,  0.18462417, -1.1665092 , -0.2097246 ,  2.5319278 ,\n",
       "       -0.41135722, -4.112002  , -0.16554652, -3.097385  , -2.0491154 ,\n",
       "        1.3159641 ,  2.7108033 , -0.6671405 ,  0.15734433, -1.3450367 ,\n",
       "        0.66420406,  2.7075136 ,  2.5028274 , -2.5337396 , -2.4513004 ,\n",
       "       -3.8098    , -0.44515482,  0.06447091, -0.9705248 ,  1.2377226 ,\n",
       "       -3.1624103 , -2.044037  ,  1.6543127 , -0.27113047, -0.93310666,\n",
       "        3.1243086 ,  0.97415537, -1.0976663 , -0.45981872, -0.703838  ,\n",
       "       -1.9956176 ,  0.5954963 , -4.513073  ,  1.0142688 , -0.83850384,\n",
       "       -0.64833117, -1.7494752 ,  2.8035305 , -0.23724718, -1.4981656 ,\n",
       "       -4.303735  ,  0.0534537 ,  0.38065517,  2.165428  ,  1.1070954 ,\n",
       "        2.519425  ,  1.8053597 ,  0.48967382, -0.10304538, -2.3480372 ,\n",
       "        2.699306  , -0.9138088 ,  1.0819453 ,  1.4957076 ,  4.373846  ,\n",
       "        3.8091147 ,  0.257506  ,  4.848016  ,  0.2955171 , -0.69672257,\n",
       "       -1.0947207 , -1.3238903 ,  0.62429506,  0.5751652 , -0.5806664 ,\n",
       "        2.332433  , -0.15329863,  0.69513357, -0.39927936, -1.1829598 ,\n",
       "        1.4681641 ,  0.82283556,  0.5922487 , -2.5134969 , -0.8753539 ,\n",
       "        2.769978  , -0.45186338, -0.01453164,  1.1683336 , -0.60013515,\n",
       "        1.7417469 , -0.5691255 , -1.1233943 ,  0.0626529 ,  1.8220749 ,\n",
       "       -2.062853  ,  4.2635036 , -4.5608673 , -1.5205206 , -0.40241256,\n",
       "        1.2695103 ,  1.1472625 , -0.5725158 ,  4.887134  , -1.250774  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reread the files, and get the vector for each file\n",
    "# feed vector into k-means algorithm to make clusters\n",
    "wordLists = MyFiles(r'/blue/acg7849/hli1/item1', tokens_only = True) # a memory-friendly iterator\n",
    "vectors = [ model.infer_vector( w ) for w in wordLists]\n",
    "print(len(vectors))\n",
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 19, 17, 9, 10, 5, 4, 4, 17, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "num_clusters = 20\n",
    "kclusterer = KMeansClusterer(num_clusters, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "\n",
    "#assigned_clusters: sequence of files and matching clusters\n",
    "assigned_clusters = kclusterer.cluster(vectors, assign_clusters=True)\n",
    "assigned_clusters[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({16: 27, 13: 18, 9: 17, 2: 16, 14: 15, 4: 14, 15: 13, 0: 11, 12: 10, 5: 9, 18: 9, 19: 7, 11: 7, 10: 6, 17: 5, 6: 5, 8: 5, 1: 3, 3: 2, 7: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(collections.Counter(assigned_clusters))\n",
    "# give length of each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add performance and do sd of performance of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>performance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14470</th>\n",
       "      <td>1750</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>6201</td>\n",
       "      <td>0.028102</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>3197</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14473</th>\n",
       "      <td>1230869</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14474</th>\n",
       "      <td>764622</td>\n",
       "      <td>0.029131</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cik  performance  year\n",
       "14470     1750     0.011929  2019\n",
       "14471     6201     0.028102  2019\n",
       "14472     3197     0.043332  2019\n",
       "14473  1230869     0.319006  2019\n",
       "14474   764622     0.029131  2019"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfm = pd.read_csv (r'performance.csv')  \n",
    "pfm = pfm.loc[pfm[\"year\"] == 2019]\n",
    "pfm[0:5] # OK\n",
    "#backup new csv\n",
    "#pfm.to_csv('pfm19.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>performance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1750</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6201</td>\n",
       "      <td>0.028102</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3197</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1230869</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>764622</td>\n",
       "      <td>0.029131</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK  performance  year\n",
       "0     1750     0.011929  2019\n",
       "1     6201     0.028102  2019\n",
       "2     3197     0.043332  2019\n",
       "3  1230869     0.319006  2019\n",
       "4   764622     0.029131  2019"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need: left join (asg5 csv, pfm19)\n",
    "asg5 = pd.read_csv (r'ASG5.csv') \n",
    "pfm = pd.read_csv (r'pfm19.csv') \n",
    "pfm = pfm.rename(columns={'cik': 'CIK'})\n",
    "pfm[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = asg5.join(pfm.set_index('CIK'), on='CIK')\n",
    "#df.join(other.set_index('key'), on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last column\n",
    "table1 = table1.iloc[: , :-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to drop all NA on performance later\n",
    "#table1.to_csv('table1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a df/csv for 200 files + 20 clusters (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_test = table1[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table1_test.to_csv('table1_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assigned_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-bb889d3a5fdf>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1_test['clstr'] = assigned_clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>coName</th>\n",
       "      <th>formtype</th>\n",
       "      <th>date</th>\n",
       "      <th>fName</th>\n",
       "      <th>length</th>\n",
       "      <th>full_link</th>\n",
       "      <th>performance</th>\n",
       "      <th>clstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1345016</td>\n",
       "      <td>YELP INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>280603.txt</td>\n",
       "      <td>152323</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/280603.txt</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1772177</td>\n",
       "      <td>KURA SUSHI USA, INC.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>275323.txt</td>\n",
       "      <td>38468</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/275323.txt</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1341766</td>\n",
       "      <td>Celsius Holdings, Inc.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>280595.txt</td>\n",
       "      <td>132197</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/280595.txt</td>\n",
       "      <td>0.110321</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1679826</td>\n",
       "      <td>Ping Identity Holding Corp.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>283125.txt</td>\n",
       "      <td>100202</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/283125.txt</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1650445</td>\n",
       "      <td>Quorum Health Corp</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>282859.txt</td>\n",
       "      <td>146425</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/282859.txt</td>\n",
       "      <td>-0.109879</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49600</td>\n",
       "      <td>EASTGROUP PROPERTIES INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>284462.txt</td>\n",
       "      <td>20617</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/284462.txt</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1174891</td>\n",
       "      <td>CalEthos, Inc.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>280098.txt</td>\n",
       "      <td>88622</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/280098.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1693696</td>\n",
       "      <td>UNITED CAPITAL CONSULTANTS INC.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>283268.txt</td>\n",
       "      <td>90266</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/283268.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1630176</td>\n",
       "      <td>GREY CLOAK TECH INC.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>282682.txt</td>\n",
       "      <td>33461</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/282682.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83350</td>\n",
       "      <td>RESERVE PETROLEUM CO</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>285179.txt</td>\n",
       "      <td>23514</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/285179.txt</td>\n",
       "      <td>-0.007474</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK                           coName formtype        date       fName  \\\n",
       "0  1345016                         YELP INC     10-K  2019-12-31  280603.txt   \n",
       "1  1772177             KURA SUSHI USA, INC.     10-K  2019-08-31  275323.txt   \n",
       "2  1341766           Celsius Holdings, Inc.     10-K  2019-12-31  280595.txt   \n",
       "3  1679826      Ping Identity Holding Corp.     10-K  2019-12-31  283125.txt   \n",
       "4  1650445               Quorum Health Corp     10-K  2019-12-31  282859.txt   \n",
       "5    49600         EASTGROUP PROPERTIES INC     10-K  2019-12-31  284462.txt   \n",
       "6  1174891                   CalEthos, Inc.     10-K  2019-12-31  280098.txt   \n",
       "7  1693696  UNITED CAPITAL CONSULTANTS INC.     10-K  2019-12-31  283268.txt   \n",
       "8  1630176             GREY CLOAK TECH INC.     10-K  2019-12-31  282682.txt   \n",
       "9    83350             RESERVE PETROLEUM CO     10-K  2019-12-31  285179.txt   \n",
       "\n",
       "   length                                full_link  performance  clstr  \n",
       "0  152323  /blue/acg7849/share/BS/item1/280603.txt     0.038182     12  \n",
       "1   38468  /blue/acg7849/share/BS/item1/275323.txt     0.019055     19  \n",
       "2  132197  /blue/acg7849/share/BS/item1/280595.txt     0.110321     17  \n",
       "3  100202  /blue/acg7849/share/BS/item1/283125.txt    -0.001723      9  \n",
       "4  146425  /blue/acg7849/share/BS/item1/282859.txt    -0.109879     10  \n",
       "5   20617  /blue/acg7849/share/BS/item1/284462.txt     0.047784      5  \n",
       "6   88622  /blue/acg7849/share/BS/item1/280098.txt          NaN      4  \n",
       "7   90266  /blue/acg7849/share/BS/item1/283268.txt          NaN      4  \n",
       "8   33461  /blue/acg7849/share/BS/item1/282682.txt          NaN     17  \n",
       "9   23514  /blue/acg7849/share/BS/item1/285179.txt    -0.007474      2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1_test['clstr'] = assigned_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1_test = table1_test.dropna()\n",
    "len(table1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>coName</th>\n",
       "      <th>formtype</th>\n",
       "      <th>date</th>\n",
       "      <th>fName</th>\n",
       "      <th>length</th>\n",
       "      <th>full_link</th>\n",
       "      <th>performance</th>\n",
       "      <th>clstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1345016</td>\n",
       "      <td>YELP INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>280603.txt</td>\n",
       "      <td>152323</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/280603.txt</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1772177</td>\n",
       "      <td>KURA SUSHI USA, INC.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>275323.txt</td>\n",
       "      <td>38468</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/275323.txt</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1341766</td>\n",
       "      <td>Celsius Holdings, Inc.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>280595.txt</td>\n",
       "      <td>132197</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/280595.txt</td>\n",
       "      <td>0.110321</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1679826</td>\n",
       "      <td>Ping Identity Holding Corp.</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>283125.txt</td>\n",
       "      <td>100202</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/283125.txt</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1650445</td>\n",
       "      <td>Quorum Health Corp</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>282859.txt</td>\n",
       "      <td>146425</td>\n",
       "      <td>/blue/acg7849/share/BS/item1/282859.txt</td>\n",
       "      <td>-0.109879</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK                       coName formtype        date       fName  \\\n",
       "0  1345016                     YELP INC     10-K  2019-12-31  280603.txt   \n",
       "1  1772177         KURA SUSHI USA, INC.     10-K  2019-08-31  275323.txt   \n",
       "2  1341766       Celsius Holdings, Inc.     10-K  2019-12-31  280595.txt   \n",
       "3  1679826  Ping Identity Holding Corp.     10-K  2019-12-31  283125.txt   \n",
       "4  1650445           Quorum Health Corp     10-K  2019-12-31  282859.txt   \n",
       "\n",
       "   length                                full_link  performance  clstr  \n",
       "0  152323  /blue/acg7849/share/BS/item1/280603.txt     0.038182     12  \n",
       "1   38468  /blue/acg7849/share/BS/item1/275323.txt     0.019055     19  \n",
       "2  132197  /blue/acg7849/share/BS/item1/280595.txt     0.110321     17  \n",
       "3  100202  /blue/acg7849/share/BS/item1/283125.txt    -0.001723      9  \n",
       "4  146425  /blue/acg7849/share/BS/item1/282859.txt    -0.109879     10  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clstr\n",
      "0     0.002738\n",
      "1     0.005545\n",
      "2     0.922740\n",
      "3     0.013788\n",
      "4     0.130794\n",
      "5     0.057892\n",
      "6     0.015134\n",
      "7          NaN\n",
      "8     0.058374\n",
      "9     0.388929\n",
      "10    0.102689\n",
      "11    6.329008\n",
      "12    0.180032\n",
      "13    3.432318\n",
      "14    0.114915\n",
      "15    0.182796\n",
      "16    1.093205\n",
      "17    1.078114\n",
      "18    0.123319\n",
      "19    0.046373\n",
      "Name: performance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate sd(perf) by clstr\n",
    "#table1_test.sql('SELECT performance,clstr, sum(performance) GROUP BY clstr')\n",
    "table1_test_sd = table1_test.groupby('clstr').std()\n",
    "table1_test_sd = table1_test_sd ['performance']# we get sd of performance\n",
    "print(table1_test_sd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (basic)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
